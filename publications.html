<!DOCTYPE html>
<html>
<head>
  <title>DatLombardo: Publications</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="assets/style/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="assets/style/pubs.css">
  <link rel="stylesheet" type="text/css" href="assets/style/footer.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

</head>

<body>
  <div class="navHead">
      <nav class="navbar navbar-expand-lg navbar-dark bg-primary">
      <a class="navbar-brand" href="index.html">Michael Lombardo</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
        <div class="collapse navbar-collapse" id="navbarColor01">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item">
              <a class="nav-link" href="lifeStory.html">Life Story</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="vitae.html">Curriculum Vitae</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="publications.html">Publications</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="MScThesis.html">M.Sc Thesis</a>
            </li>
          </ul>
        </div>
    </nav>
  </div>
  <div class="card mb-3">
    <h1 class="card-header" >
      <ol class="breadcrumb">
      <li class="breadcrumb-item"><a href="index.html">Home</a></li>
      <li class="breadcrumb-item">Publications</li>
    </ol>
    </h1>
    <div class="card-body">
      <h2 class="card-title">Presentation Gallery</h2>
    </div>

  <!-- Slideshow container -->
  <div class="slideshow-container">
    <!-- Full-width images with number and caption text -->
    <div class="mySlides fade">
      <img src="assets/publications/undergradShowcase2017.png" class="img-responsive">
      <div class="slideText">Summer Undergraduate Research Showcase at Ontario Tech University, 2017</div>
    </div>

    <div class="mySlides fade">
      <img src="assets/publications/UndergradShowcase2018.png" class="img-responsive">
      <div class="slideText">Summer Undergraduate Research Showcase at Ontario Tech University, 2018</div>
    </div>

    <div class="mySlides fade">
      <img src="assets/publications/PublicInc.png" class="img-responsive">
      <div class="slideText">Public Inc. Donor Appreciation Reception in Toronto, 2018</div>
    </div>

    <div class="mySlides fade">
      <img src="assets/publications/donorShowcaseOshawa.png" class="img-responsive">
      <div class="slideText">Donor Appreciation Night in Downtown Oshawa, 2018</div>
    </div>
    <div class="mySlides fade">
      <img src="assets/publications/CSearch.png" class="img-responsive">
      <div class="slideText">CSearch Conference at Queens University, 2018</div>
    </div>
    <div class="mySlides fade">
      <img src="assets/publications/BScPosterPres.png" class="img-responsive">
      <div class="slideText">Undergraduate Honours Thesis Showcase at Ontario Tech University, 2019</div>
    </div>


  </div>
  <br>
  <div style="text-align:center">
    <span class="dot"></span>
    <span class="dot"></span>
    <span class="dot"></span>
    <span class="dot"></span>
    <span class="dot"></span>
    <span class="dot"></span>
  </div>

  </div>

  <div class="card-body">
    <h1 class="card-title" id="posterTitle">Disserations</h1>
  </div>
  <div class="card">
    <div class="card-body">
      <h4 class="card-title">Parsing Genetic Models</h4>
      <h5 class="card-subtitle mb-2"><a href="http://vclab.science.uoit.ca/">Visual Computing Lab </a>- Supervisor: Dr. Faisal Qureshi</h5>
      <h6 class="card-subtitle mb-2 text-muted">Successfully Defended on January 6, 2022 - University of Ontario Institute of Technology</h6>

      <p class="card-text">Applications of computer vision have seen great success recently, yet there are few approaches dealing with visual illustrations. We propose a collection of computer vision applications for parsing genetic models. Genetic models are a visual illustration often used in the biological sciences literature. These are used to demonstrate how a discovery fits into what is already known about a biological system. A system that determines the interactions present in a genetic model can be valuable to researchers studying such interactions. The proposed system contains three parts. First, a triplet network is deployed to decide whether or not a figure is a genetic model. Second, a popular object detection network YOLOvS is trained to locate regions of interest within genetic models using various deep learning training techniques. Lastly, we propose an algorithm that can infer the relationships between the pairs of genes or textual features present in the genetic model.</p>
      <a href="https://ir.library.ontariotechu.ca/handle/10155/1421" class="card-link">Library Link</a>
    </div>
  </div>

  <div class="card-body">
    <h1 class="card-title" id="posterTitle">Published Posters</h1>
  </div>
  <div class="card">
    <div class="card-body">
      <h4 class="card-title">Understanding Gene Model Maps</h4>
      <h5 class="card-subtitle mb-2"><a href="http://vclab.science.uoit.ca/">Visual Computing Lab </a>- Supervisor: Dr. Faisal Qureshi</h5>
      <h6 class="card-subtitle mb-2 text-muted">April 21, 2021 - Ontario Workshop on Computer Vision</h6>
      <p class="card-text">We propose a computer vision system for parsing gene model maps. Gene model maps are visual illustrations (often used in the biological sciences literature) that are used to demonstrate how a discovery fits into what is already known about a biological system. Furthermore, determining what interactions occur between a set of genes is valuable for researchers. Our work comprises three parts. First, we train a triplet network to decide whether or not a figure is a gene model map. Next, we use Google's Cloud Vision optical character recognition to extract the text of genes occurring within the gene model map. Secondly, we repurpose the architecture of YOLOv5 trained on our synthetic dataset of biological diagrams to find locations of genes and relationships. Lastly, we proposed a deep network that is able to infer the relationships between the gene pairs present in the gene model. Components of this system power the search functionality of Bio-Analytic Resource for Plant Biology tool at the University of Toronto.</p>
      <a href="assets/posters/UGMM.pdf" class="card-link">PDF</a>
    </div>
  </div>

  <div class="card">
    <div class="card-body">
      <h4 class="card-title">Exploring LSTMs on Video Analysis</h4>
      <h5 class="card-subtitle mb-2"><a href="http://vclab.science.uoit.ca/">Visual Computing Lab </a>- Supervisor: Dr. Faisal Qureshi</h5>
      <h6 class="card-subtitle mb-2 text-muted">April 10, 2019 - Ontario Tech University Undergraduate Honours Thesis Showcase</h6>
      <p class="card-text">Video has rapidly become one of the most common and largest sources of visual information. Although merely effortless to record large amounts of video data, raw videos often require significant editing until being best suited for viewing. User edited videos often only include segments of the raw video which are deemed to be interesting by the editor. State-of-the-art video summarization methods have accomplished generating high-quality summaries from raw videos. Attempting to beat current state-of-the-art video summarization methods is a daunting task. For this reason, my honours thesis focuses towards attempting to discover different new methods for video segmentation. In this honours thesis, I present my experiments using long short term memory (LSTM) cells to successfully detect boundaries in a video, and rate the interestingness score of the final frame, given a sequence of frames from a video. Using the TVSum50 dataset to conduct these experiments, I conclude that an LSTM based model can learn temporal dependencies within a sequence of frames to successfully detect boundaries and rate the Interestingness of a frame.</p>
      <a href="assets/posters/ELOVS.pdf" class="card-link">PDF</a>
    </div>
  </div>

  <div class="card">
    <div class="card-body">
      <h4 class="card-title">Content Aware Video Summarization</h4>
      <h5 class="card-subtitle mb-2"><a href="http://vclab.science.uoit.ca/">Visual Computing Lab </a>- Supervisor: Dr. Faisal Qureshi</h5>
      <h6 class="card-subtitle mb-2 text-muted">August 23, 2018 - University of Ontario Institute of Technology Undergraduate Research Showcase</h6>
      <p class="card-text">Video has rapidly become one of the most common and largest sources of visual information. This explosion of accessible video data through many mediums such as smartphones, video cameras, webcams, etc. has brought us to an age of big video data. Although merely effortless to record large amounts of video data, raw videos often require significant editing until being best suited for viewing. User edited videos often only include segments of the raw video which are deemed to be interesting by the editor. State-of-the-art video summarization methods have accomplished generating high-quality summaries from raw videos. How can we use frame-level features to improve the summarization by changing the velocity of the video at different segments?</p>
      <a href="assets/posters/CAVS.pdf" class="card-link">PDF</a>
    </div>
  </div>

  <div class="card">
    <div class="card-body">
      <h4 class="card-title">Exploratory Data Analysis on Student Retention</h4>
      <h5 class="card-subtitle mb-2"><a href="http://vialab.science.uoit.ca/">Visualization for Information Analysis Lab </a>- Supervisor: Dr. Christopher Collins</h5>
      <h6 class="card-subtitle mb-2 text-muted">August 23, 2017 - University of Ontario Institute of Technology Undergraduate Research Showcase</h6>
      <p class="card-text">The UOIT Registrar’s Office reached out to the Vialab to build a to visualize student retention data for exploratory data analysis with an emphasis on patterns which are predictive of student withdrawal. The RetentionVis tool relies on user interaction through application of filters to the visualizations to assist the Registrar's Office to answer the question: ‘Why are students dropping out?’. All post-secondary intuitions' main source of revenue is tuition from undergraduate studies. Student retention is key to the success of any institution, not only for revenue but for their reputation. The dashboard is an online interactive tool created in JavaScript’s D3 library hosted by UOIT. The tool requires the user to make various selections including: faculties/programs, years, timeslots, and GPA ranges of interest with the goal of finding opportunities for improvement at UOIT.</p>
      <a href="assets/posters/EDA.pdf" class="card-link">PDF</a>
    </div>
  </div>
<script>
var slideIndex = 0;
showSlides();

function showSlides() {
  var i;
  var slides = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("dot");
  for (i = 0; i < slides.length; i++) {
    slides[i].style.display = "none";
  }
  slideIndex++;
  if (slideIndex > slides.length) {slideIndex = 1}
  for (i = 0; i < dots.length; i++) {
    dots[i].className = dots[i].className.replace(" active", "");
  }
  slides[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " active";
  setTimeout(showSlides, 2000); // Change image every 2 seconds
}
</script>
</body>
<footer class="page-footer">
  <div class="container-fluid text-center text-md-center">
    <div class="row">
      <div class="col-md-12 mt-md-0 mt-3">
        <h5 class="text">Connect With Me!</h5>
        <div class="d-flex justify-content-center">
          <ul class="social-network social-circle">
              <li><a onclick="location.href='https://www.facebook.com/michael.lombardo.129'" style="cursor: pointer;" class="icoFacebook" title="Facebook"><i class="fa fa-facebook"></i></a></li>
              <li><a onclick="location.href='https://twitter.com/DatLombardo'" style="cursor: pointer;" class="icoTwitter" title="Twitter"><i class="fa fa-twitter"></i></a></li>
              <li><a onclick="location.href='https://www.linkedin.com/in/michael-lombardo-78650a107/'" style="cursor: pointer;" class="icoLinkedin" title="Linkedin"><i class="fa fa-linkedin"></i></a></li>
              <li><a onclick="location.href='https://www.instagram.com/datlombardo/'" style="cursor: pointer;" class="icoInstagram" title="Instagram"><i class="fa fa-instagram"></i></a></li>
              <li><a onclick="location.href='https://github.com/DatLombardo'" style="cursor: pointer;" class="icoGithub" title="GitHub"><i class="fa fa-github"></i></a></li>
          </ul>
        </div>
    </div>
  </div>
  <div class="footer-copyright text-center py-3">Copyright © Michael Lombardo 2021</div>
</footer>
<script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" integrity="sha384-w1Q4orYjBQndcko6MimVbzY0tgp4pWB4lZ7lr30WKz0vr/aWKhXdBNmNb5D92v7s" crossorigin="anonymous"></script>
</html>
